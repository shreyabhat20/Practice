{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SYtV3GvAKBkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eabbf72-58e5-4491-9888-209a43d422f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/138.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m122.9/138.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "#OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "\n"
      ],
      "metadata": {
        "id": "bMVayXfMKHq1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages.ai import AIMessage\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from typing import Literal, Annotated\n",
        "from collections.abc import Iterable\n",
        "from random import randint\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import TypedDict"
      ],
      "metadata": {
        "id": "trR3OBtYKzrw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OrderState(TypedDict):\n",
        "    \"\"\"State representing the customer's order conversation.\"\"\"\n",
        "    messages: Annotated[list, add_messages]\n",
        "    order: list[str]\n",
        "    finished: bool\n",
        "\n",
        "# System instruction\n",
        "BARISTABOT_SYSINT = (\n",
        "    \"system\",\n",
        "    \"You are a BaristaBot, an interactive cafe ordering system. A human will talk to you about the \"\n",
        "    \"available products you have and you will answer any questions about menu items (and only about \"\n",
        "    \"menu items - no off-topic discussion, but you can chat about the products and their history). \"\n",
        "    \"The customer will place an order for 1 or more items from the menu, which you will structure \"\n",
        "    \"and send to the ordering system after confirming the order with the human. \"\n",
        "    \"\\n\\n\"\n",
        "    \"Add items to the customer's order with add_to_order, and reset the order with clear_order. \"\n",
        "    \"To see the contents of the order so far, call get_order (this is shown to you, not the user) \"\n",
        "    \"Always confirm_order with the user (double-check) before calling place_order. Calling confirm_order will \"\n",
        "    \"display the order items to the user and returns their response to seeing the list. Their response may contain modifications. \"\n",
        "    \"Always verify and respond with drink and modifier names from the MENU before adding them to the order. \"\n",
        "    \"If you are unsure a drink or modifier matches those on the MENU, ask a question to clarify or redirect. \"\n",
        "    \"You only have the modifiers listed on the menu. \"\n",
        "    \"Once the customer has finished ordering items, Call confirm_order to ensure it is correct then make \"\n",
        "    \"any necessary updates and then call place_order. Once place_order has returned, thank the user and \"\n",
        "    \"say goodbye!\"\n",
        "    \"\\n\\n\"\n",
        "    \"If any of the tools are unavailable, you can break the fourth wall and tell the user that \"\n",
        "    \"they have not implemented them yet and should keep reading to do so.\",\n",
        ")\n",
        "\n",
        "WELCOME_MSG = \"Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\""
      ],
      "metadata": {
        "id": "lUeRju4VLAC7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "kAQjE7UKLDCO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_menu() -> str:\n",
        "    \"\"\"Provide the latest up-to-date menu.\"\"\"\n",
        "    return \"\"\"\n",
        "    MENU:\n",
        "\n",
        "    â˜• Coffee Drinks:\n",
        "    - Espresso\n",
        "    - Americano\n",
        "    - Cold Brew\n",
        "\n",
        "    â˜• Coffee Drinks with Milk:\n",
        "    - Latte\n",
        "    - Cappuccino\n",
        "    - Cortado\n",
        "    - Macchiato\n",
        "    - Mocha\n",
        "    - Flat White\n",
        "\n",
        "    ðŸµ Tea Drinks:\n",
        "    - English Breakfast Tea\n",
        "    - Green Tea\n",
        "    - Earl Grey\n",
        "\n",
        "    ðŸµ Tea Drinks with Milk:\n",
        "    - Chai Latte\n",
        "    - Matcha Latte\n",
        "    - London Fog\n",
        "\n",
        "    ðŸ§ƒ Other Drinks:\n",
        "    - Steamer\n",
        "    - Hot Chocolate\n",
        "\n",
        "    ðŸ¥ Breakfast Options:\n",
        "    - Croissant (plain, almond, chocolate)\n",
        "    - Muffin (blueberry, banana nut, chocolate chip)\n",
        "    - Bagel (plain, sesame, everything) â€“ with butter or cream cheese\n",
        "    - Breakfast Sandwich (egg & cheese, sausage & egg, veggie)\n",
        "    - Oatmeal â€“ with optional toppings (honey, raisins, banana slices)\n",
        "\n",
        "    âž• Modifiers:\n",
        "    - Milk options: Whole, 2%, Oat, Almond, 2% Lactose Free; Default: Whole\n",
        "    - Espresso shots: Single, Double, Triple, Quadruple; Default: Double\n",
        "    - Caffeine: Decaf, Regular; Default: Regular\n",
        "    - Hot-Iced: Hot, Iced; Default: Hot\n",
        "    - Sweeteners (option to add one or more): vanilla sweetener, hazelnut sweetener, caramel sauce, chocolate sauce, sugar free vanilla sweetener\n",
        "    - Special requests: Any reasonable modification that does not involve items not on the menu (e.g., 'extra hot', 'half caff', 'extra foam')\n",
        "\n",
        "    â„¹ï¸ Notes:\n",
        "    - \"Dirty\" means add a shot of espresso to a drink that doesn't usually have it, like a \"Dirty Chai Latte\".\n",
        "    - \"Regular milk\" = whole milk.\n",
        "    - \"Sweetened\" = add regular sugar.\n",
        "    - Soy milk is out of stock today.\n",
        "    \"\"\"\n",
        "\n",
        "@tool\n",
        "def add_to_order(drink: str, modifiers: Iterable[str]) -> str:\n",
        "    \"\"\"Adds the specified drink to the customer's order, including any modifiers.\"\"\"\n",
        "    pass\n",
        "\n",
        "@tool\n",
        "def confirm_order() -> str:\n",
        "    \"\"\"Asks the customer if the order is correct.\"\"\"\n",
        "    pass\n",
        "\n",
        "@tool\n",
        "def get_order() -> str:\n",
        "    \"\"\"Returns the users order so far. One item per line.\"\"\"\n",
        "    pass\n",
        "\n",
        "@tool\n",
        "def clear_order():\n",
        "    \"\"\"Removes all items from the user's order.\"\"\"\n",
        "    pass\n",
        "\n",
        "@tool\n",
        "def place_order() -> int:\n",
        "    \"\"\"Sends the order to the barista for fulfillment.\"\"\"\n",
        "    pass\n",
        "\n",
        "@tool\n",
        "def update_order_item(index: int, new_item: str) -> str:\n",
        "    \"\"\"Updates an item at the specified index (1-based) with a new string.\"\"\"\n",
        "    pass\n",
        "\n",
        "@tool\n",
        "def remove_order_item(index: int) -> str:\n",
        "    \"\"\"Removes the item at the specified index (1-based).\"\"\"\n",
        "    pass\n",
        "\n",
        "def order_node(state: OrderState) -> OrderState:\n",
        "    \"\"\"The ordering node. This is where the order state is manipulated.\"\"\"\n",
        "    tool_msg = state.get(\"messages\", [])[-1]\n",
        "    order = state.get(\"order\", [])\n",
        "    outbound_msgs = []\n",
        "    order_placed = False\n",
        "\n",
        "    for tool_call in tool_msg.tool_calls:\n",
        "        if tool_call[\"name\"] == \"add_to_order\":\n",
        "            modifiers = tool_call[\"args\"][\"modifiers\"]\n",
        "            modifier_str = \", \".join(modifiers) if modifiers else \"no modifiers\"\n",
        "            order.append(f'{tool_call[\"args\"][\"drink\"]} ({modifier_str})')\n",
        "            response = \"\\n\".join(order)\n",
        "\n",
        "        elif tool_call[\"name\"] == \"confirm_order\":\n",
        "            response = \"User will confirm in next message.\"\n",
        "\n",
        "        elif tool_call[\"name\"] == \"get_order\":\n",
        "            response = \"\\n\".join(order) if order else \"(no order)\"\n",
        "\n",
        "        elif tool_call[\"name\"] == \"clear_order\":\n",
        "            order.clear()\n",
        "            response = \"Order cleared.\"\n",
        "\n",
        "        elif tool_call[\"name\"] == \"place_order\":\n",
        "            order_text = \"\\n\".join(order)\n",
        "            print(\"Sending order to kitchen!\")\n",
        "            print(order_text)\n",
        "            order_placed = True\n",
        "            response = str(randint(1, 5))  # ETA in minutes\n",
        "\n",
        "        elif tool_call[\"name\"] == \"update_order_item\":\n",
        "            index = int(tool_call[\"args\"][\"index\"]) - 1  # Explicitly cast to int\n",
        "            new_item = tool_call[\"args\"][\"new_item\"]\n",
        "            if 0 <= index < len(order):\n",
        "                old = order[index]\n",
        "                order[index] = new_item\n",
        "                response = f\"Updated item {index + 1}: '{old}' â†’ '{new_item}'\"\n",
        "            else:\n",
        "                response = f\"Invalid index: {index + 1}\"\n",
        "\n",
        "        elif tool_call[\"name\"] == \"remove_order_item\":\n",
        "            index = int(tool_call[\"args\"][\"index\"]) - 1  # Explicitly cast to int\n",
        "            if 0 <= index < len(order):\n",
        "                removed = order.pop(index)\n",
        "                response = f\"Removed item {index + 1}: '{removed}'\"\n",
        "            else:\n",
        "                response = f\"Invalid index: {index + 1}\"\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError(f'Unknown tool call: {tool_call[\"name\"]}')\n",
        "\n",
        "        outbound_msgs.append(\n",
        "            ToolMessage(\n",
        "                content=response,\n",
        "                name=tool_call[\"name\"],\n",
        "                tool_call_id=tool_call[\"id\"],\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return {\"messages\": outbound_msgs, \"order\": order, \"finished\": order_placed}\n",
        "\n",
        "def chatbot_with_tools(state: OrderState) -> OrderState:\n",
        "    \"\"\"The chatbot with tools.\"\"\"\n",
        "    defaults = {\"order\": [], \"finished\": False}\n",
        "\n",
        "    if state[\"messages\"]:\n",
        "        new_output = llm_with_tools.invoke([BARISTABOT_SYSINT] + state[\"messages\"])\n",
        "    else:\n",
        "        new_output = AIMessage(content=WELCOME_MSG)\n",
        "\n",
        "    return defaults | state | {\"messages\": [new_output]}\n",
        "\n",
        "def human_node(state: OrderState) -> OrderState:\n",
        "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "    print(\"Model:\", last_msg.content)\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
        "        state[\"finished\"] = True\n",
        "\n",
        "    return state | {\"messages\": [(\"user\", user_input)]}\n",
        "\n",
        "def maybe_exit_human_node(state: OrderState) -> Literal[\"chatbot\", \"__end__\"]:\n",
        "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
        "    if state.get(\"finished\", False):\n",
        "        return END\n",
        "    else:\n",
        "        return \"chatbot\"\n",
        "\n",
        "def maybe_route_to_tools(state: OrderState) -> str:\n",
        "    \"\"\"Route between chat and tool nodes if a tool call is made.\"\"\"\n",
        "    if not (msgs := state.get(\"messages\", [])):\n",
        "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
        "\n",
        "    msg = msgs[-1]\n",
        "\n",
        "    if state.get(\"finished\", False):\n",
        "        return END\n",
        "    elif hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
        "        if any(tool[\"name\"] in tool_node.tools_by_name.keys() for tool in msg.tool_calls):\n",
        "            return \"tools\"\n",
        "        else:\n",
        "            return \"ordering\"\n",
        "    else:\n",
        "        return \"human\""
      ],
      "metadata": {
        "id": "D9MpkEBYLIcJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-tools will be invoked automatically by the ToolNode\n",
        "auto_tools = [get_menu]\n",
        "tool_node = ToolNode(auto_tools)\n",
        "\n",
        "# Order-tools will be handled by the order node - FIXED: Added missing tools\n",
        "order_tools = [add_to_order, confirm_order, get_order, clear_order, place_order, update_order_item, remove_order_item]\n",
        "\n",
        "# The LLM needs to know about all of the tools\n",
        "llm_with_tools = llm.bind_tools(auto_tools + order_tools)\n",
        "\n",
        "# Build the graph\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Nodes\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_tools)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_node(\"ordering\", order_node)\n",
        "\n",
        "# Edges\n",
        "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(\"ordering\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "graph_with_order_tools = graph_builder.compile()"
      ],
      "metadata": {
        "id": "1sx1SCHkLLti"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"recursion_limit\": 100}\n",
        "state = graph_with_order_tools.invoke({\"messages\": []}, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shxLJfZ5LOly",
        "outputId": "180a9cb7-ee6b-455b-c102-cf7b1e954315"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Welcome to the BaristaBot cafe. Type `q` to quit. How may I serve you today?\n",
            "User: What all do you serve\n",
            "Model: We serve a variety of coffee drinks, tea drinks, and other beverages, as well as breakfast options.\n",
            "\n",
            "Our coffee drinks include Espresso, Americano, and Cold Brew. We also have coffee drinks with milk like Latte, Cappuccino, Cortado, Macchiato, Mocha, and Flat White.\n",
            "\n",
            "For tea lovers, we offer English Breakfast Tea, Green Tea, and Earl Grey. Our tea drinks with milk include Chai Latte, Matcha Latte, Latte, and London Fog.\n",
            "\n",
            "Other drinks on our menu are Steamer and Hot Chocolate.\n",
            "\n",
            "For breakfast, you can choose from Croissants (plain, almond, chocolate), Muffins (blueberry, banana nut, chocolate chip), Bagels (plain, sesame, everything) with butter or cream cheese, Breakfast Sandwiches (egg & cheese, sausage & egg, veggie), and Oatmeal with optional toppings.\n",
            "\n",
            "We also have various modifiers like milk options (Whole, 2%, Oat, Almond, 2% Lactose Free), espresso shots (Single, Double, Triple, Quadruple), caffeine options (Decaf, Regular), and temperature (Hot, Iced). You can also add sweeteners like vanilla, hazelnut, caramel, chocolate, or sugar-free vanilla. We also accommodate special requests.\n",
            "User: I wish to have a muffin\n",
            "Model: What kind of muffin would you like? We have blueberry, banana nut, and chocolate chip.\n",
            "User: A choco muffin will do\n",
            "Model: Great! I've added a Chocolate Chip Muffin to your order. Anything else?\n",
            "User: A cup of tea\n",
            "Model: What kind of tea would you like? We have English Breakfast Tea, Green Tea, and Earl Grey. We also have Chai Latte, Matcha Latte, and London Fog, which are tea drinks with milk.\n",
            "User: 2 green teas\n",
            "Model: I've added two Green Teas to your order. Would you like anything else?\n",
            "User: No, thanks\n",
            "Model: I've added a Chocolate Chip Muffin and two Green Teas to your order. Does that sound right?\n",
            "User: Sure\n",
            "Sending order to kitchen!\n",
            "Chocolate Chip Muffin (no modifiers)\n",
            "Green Tea (no modifiers)\n",
            "Green Tea (no modifiers)\n"
          ]
        }
      ]
    }
  ]
}